---
title: "Calc. Riverdistances"
author: "Ryan Peek"
date: '`r format(Sys.time(), "%Y-%b-%d")`'
output:
  html_document:
    fig_caption: yes
    highlight: tango
    theme: flatly
    toc: yes
    toc_float: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
knitr::opts_knit$set(root.dir = normalizePath("../"))

# load libraries
suppressMessages({
  library(tidyverse);
  library(lubridate);
  library(magrittr);
  library(huxtable);
  library(sf);
  library(maptools);
  library(riverdist);
  #devtools::install_github("hrbrmstr/albersusa") (see here https://github.com/hrbrmstr/albersusa)
  library(albersusa)
})

options(scipen = 12) # to avoid issues with paste functions, & joining on subsample number
```

# Understand Spatial Patterns with Genomic Data

Interestingly, the relationship between F<sub>ST</sub> and `NHD Stream order` (strahler) is strikingly different between regulated and unregulated watersheds. The pattern is less clear in $\theta_ \Delta$ vs. `NHD Stream Order` but there is less diversity in the regulated sites, and the trend line appears sightly steeper.


<!-- Code for these figs is below but can use these standalone figs too

![fst_vs_nhdorder]("figs/mean_fst_vs_streamorder.png")
![theta_vs_nhdorder]("figs/theta_diff_vs_streamorder.png")

but probably worth showing all figs-->

```{r fig_overview, echo=F, eval=T}

metadat<- read_csv("data_output/rapture06_metadata_revised.csv") %>% arrange(Seq)

load("data_output/mod_theta100k_fst_dists_yub_amer_bear.rda") # mean values for all

# plot
library(hrbrthemes) # for fanciness
#extrafont::loadfonts() only if the above doesn't run
#import_roboto_condensed()

# FST by distance:
ggplot() + 
  stat_smooth(data = mod_dat_nhd,
              aes(y= (fst_mean/(1-fst_mean)), x=mean_km, group=REG, color=REG),
              method = "glm", show.legend = T, lty=2, lwd=0.8, alpha=0.5 ) +
  
  geom_point(data=mod_dat_nhd, aes(y= (fst_mean/(1-fst_mean)), 
                                   x=mean_km, fill=REG),
             show.legend = T, pch=21, size=4) +
  labs(x="Mean River Distance (km)",
       y=expression(paste("Mean F" ["ST"], " / (1 - Mean F" ["ST"],")"))) +
  #facet_grid(REG~., scales = "fixed") + 
  theme_bw(base_family = "Roboto Condensed")

ggsave(filename = "figs/fst_vs_meandist_regunreg.png", width = 9, height = 6, units = "in", dpi=200)

# plot Fst vs dist colored by theta_diff
#plotly::ggplotly(

ggplot() + 
  stat_smooth(data = mod_dat_nhd,
              aes(y= (fst_mean/(1-fst_mean)), x=mean_km, group=REG, color=REG),
              method = "glm", show.legend = T, lty=2, lwd=0.8, alpha=0.5 ) +
  
  geom_point(data=mod_dat_nhd, aes(y= (fst_mean/(1-fst_mean)), 
                                   x=mean_km, fill=Tdiff, label=Locality),
             show.legend = T, pch=21, size=4) +
  
  # spectral for discrete
  scale_fill_distiller(palette = "Spectral", name=expression(paste(theta[Delta]))) + 
  
  labs(title=expression(paste("Mean F" ["ST"], " vs Mean Dist_km")),
       y=expression(paste("Mean F" ["ST"], " / (1 - Mean F" ["ST"],")"))) +
  facet_grid(REG~., scales = "fixed") + 
  theme_bw(base_family = "Roboto Condensed")
  #theme_ipsum_rc(grid="Y", axis = T)
#)

# plot elev vs. Tdiff
ggplot() + 
  stat_smooth(data=mod_dat_nhd, aes(x=elev_m, y=Tdiff, group=REG), method = "glm", color="darkblue", lty=2) +
  geom_point(data=mod_dat_nhd, aes(x=elev_m, y=Tdiff, color=REG), size=3, show.legend = T) +
  facet_grid(REG~.) +
  labs(title=expression(paste(theta [Delta], "= (", theta [pi], "-", theta [w], ") vs. Elev_m")),
       y=expression(paste(theta [Delta]))) +
  theme_bw(base_family = "Roboto Condensed")

# plot Tdiff vs. Fst/dist
ggplot() + 
  stat_smooth(data=mod_dat_nhd, aes(y=fst_mean/(1-fst_mean)/mean_km, x=Tdiff, group=REG), method = "glm",
              color="darkblue", lwd=0.8, lty=2) +
  geom_point(data=mod_dat_nhd, aes(y=fst_mean/(1-fst_mean)/mean_km, x=Tdiff, color=REG), size=3, show.legend = T) +
  #facet_grid(REG~., scales = "free_x") +
  labs(title=expression(paste(theta [Delta], "= (", theta [pi], "-", theta [w], ") vs. ", 
                              "Mean F" ["ST"], " / (1 - Mean F" ["ST"],")")),
       x=expression(paste(theta [Delta])),
       y=expression(paste("Mean F" ["ST"], " / (1 - Mean F" ["ST"],")"))) +
  theme_bw(base_family = "Roboto Condensed")

# plot elev vs. Fst/dist
ggplot() + 
  stat_smooth(data=mod_dat_nhd, aes(y=fst_mean/(1-fst_mean)/mean_km, x=elev_m, group=REG), col="darkblue", method = "glm", lty=2, lwd=0.8) +
  geom_point(data=mod_dat_nhd, aes(y=fst_mean/(1-fst_mean)/mean_km, x=elev_m, color=REG), size=3, show.legend = T) +
  #facet_grid(REG~., scales = "free_y") +
  labs(title=expression(paste("(Mean F" ["ST"], "/" ,"Mean Dist_km) vs. Elevation (m)")),
       y=expression(paste("Mean F" ["ST"], "/", "Mean Dist (km)"))) +
  theme_bw(base_family = "Roboto Condensed")

# plot stream order vs. fst
ggplot() + 
  stat_smooth(data=mod_dat_nhd, aes(y=fst_mean/(1-fst_mean)/mean_km, x=NHD_StreamOrder, group=REG, color=REG), method = "glm", lty=2, lwd=0.8) +
  geom_point(data=mod_dat_nhd, aes(y=fst_mean/(1-fst_mean)/mean_km, x=NHD_StreamOrder, shape=REG, color=watershed), size=3, show.legend = T) +
  #facet_grid(REG~., scales = "free_x") +
  labs(title=expression(paste("(Mean F" ["ST"], "/" ,"Mean Dist_km) vs. Stream Order")),
       y=expression(paste("Mean F" ["ST"], "/", "Mean Dist (km)"))) +
  theme_bw(base_family = "Roboto Condensed")
  
#ggsave(filename = "figs/mean_fst_vs_streamorder.png", width = 9, height = 6, units = "in", dpi=200)

# plot stream order vs. thetas
ggplot() + 
  stat_smooth(data=mod_dat_nhd, method = "glm", aes(y=Tdiff, x=NHD_StreamOrder, group=REG, color=REG),
              lty=1, lwd=0.8) +
  facet_grid(REG~.) +
  geom_point(data=mod_dat_nhd, aes(y=Tdiff, x=NHD_StreamOrder, color=REG), size=3, show.legend = T) +
  geom_hline(yintercept = 0, lty=2, color="gray50")+
  labs(title=expression(paste(theta [Delta], " vs. Stream Order")),
       y=expression(paste(theta [Delta]))) +
  theme_bw(base_family = "Roboto Condensed")
  #theme_ipsum_rc(grid="Y", axis = T)
#ggsave(filename = "figs/theta_diff_vs_streamorder.png", width = 9, height = 6, units = "in", dpi=200)

```

# Spatial River Network Data

There are two major steps that need to occur in order to evaluate impairment (something like the *Obs. to Exp* ratio) within the river network, first we need to associate a given reach or sample site with a USGS Gage to extract flow data. See the section on [**Nearest Points**](#snaptopoints). The second step is to calculate river distances between sites (used for pairwise F<sub>ST</sub> analysis), as this frog species tends to move along or within the river corridor, they may encounter various levels of resistance or connectivity due to the flow regime. In particular, the comparison we are most interested in is the effect the mainstem (*e.g., stream order 4 or greater*) hydrology, and how the level of impairment effects genomic connectivity. See the section on [**River Distances**](#riverdistances).

## Snap Points to Nearest USGS Gages {#snaptopoints}

Need to load USGS gage sites (for observed), and calculate nearest gage for each study site, or Locality. There are a few options to do this, but the two primary packages used for this analysis are `SearchTrees` and a *k nearest-neighbor lookup*, or the `gdist` function in the `Imap` package. 

### Nearest Points Using `knn lookup`

This code determines the nearest-n points to an existing set of points. Here, we can use it to find/assign the nearest USGS gage to our existing sampling sites.

```{r usgs_nearest_knnlookup, echo=F, eval=T}

load("data_output/frogs_gages_unimp_OE_dat.rda") # all data for OE and frog points

library(SearchTrees)

# grep all sites in Sierras?
gages_sierra <- filter(gages_oe, grepl(pattern = "AMER|BEAR|FEAT|YUBA|DEER",site)) %>% 
  filter(!site_no %in% c("11200800", "11230500", "11230530", "11451715", "11451720", "11407150",
                         "11421000", "1424000", "11312000", "11425000", "11292900", "11315900",
                         "11316000", "11316100","11335655"))
gage_sierra_ids <- gages_sierra$gageID

# how to merge with O_E
unimp_sierra <- filter(unimp_rabo, EcoRegion =="Sierra Nevada" | EcoRegion=="Sierra/Basin Range")
frogs_sierra <- filter(frog_pts_nhd, EcoRegion =="Sierra Nevada" | EcoRegion=="Sierra/Basin Range") %>% select(Locality, COMID_1, everything())

# make GAGE data sp:
#gages_sierra.sp <- as(gages_sierra, "Spatial")

# make frog data sf: 
frogs_sierra <- st_as_sf(frogs_sierra, 
                          coords = c("lon", "lat"), 
                          remove = F, crs = 4326)


## Find indices of the two nearest points in A to each of the points in B
tree <- createTree(st_coordinates(gages_sierra))
inds <- knnLookup(tree, newdat=st_coordinates(frogs_sierra), k=2) # can be 2 or more

## Show that it worked
plot(st_coordinates(gages_sierra), pch=1, cex=1.5)
points(st_coordinates(frogs_sierra)[c(4,5,9,15, 25),],
       bg=c("orange","maroon","purple","yellow", "green"), 
       pch=22, cex=1.5)

## Plot two nearest neigbors
points(st_coordinates(gages_sierra)[inds[4,],], pch=16, col=adjustcolor("orange", alpha=0.9))
points(st_coordinates(gages_sierra)[inds[5,],], pch=16, col=adjustcolor("maroon", alpha=0.9))
points(st_coordinates(gages_sierra)[inds[9,],], pch=16, col=adjustcolor("purple", alpha=0.7))
points(st_coordinates(gages_sierra)[inds[25,],], pch=16, col=adjustcolor("green", alpha=0.7))

# re-join the index of nearest gages for usage in model:
head(frogs_sierra)
inds_df <- tibble("gage01"=inds[,1], "gage02"=inds[,2],
                  "gage01_site_no"=paste0("T",gages_sierra$site_no[inds[,1]]),
                  "gage02_site_no"=paste0("T",gages_sierra$site_no[inds[,2]]))
head(inds_df)
 
# # join to data index and locality data
frogs_sierra_gage <- bind_cols(frogs_sierra, inds_df)
head(frogs_sierra_gage[,c(1,2,6:9,21:25)])
 
# now join to OE data (based on nearest gage)
frogs_sierra_oe <- left_join(frogs_sierra_gage, OE, by=c("gage01_site_no"="ID"))

#save(frogs_sierra_oe, file="data_output/frogs_sierra_oe.rda")

```

<!--Here's a leaflet map of all the USGS sites in the Northern Sierra:

```{r leaflet USGS map, eval=F, echo=F}

#quick plot:
suppressPackageStartupMessages({
  library(leaflet)
  library(htmltools)
})

# load additional data
h8 <- st_read("data_output/shps/HUC8_named_westcoast.shp", quiet = T)
frogs<- read_csv("data_output/rapture06_metadata_revised.csv")

# MAP
aMAP<-leaflet() %>% #width = "100%", height="100%"
  addTiles() %>% 
  #setView(lng = -120.8, lat = 39, zoom = 5) %>%  # set to Auburn/Colfax, zoom 5 for CA 
  addProviderTiles("Esri.WorldTopoMap", group = "Topo") %>%
  addProviderTiles("Esri.WorldImagery", group = "ESRI Aerial") %>%

  # huc8
  addPolygons(data=h8, group="HUC8", color="darkblue", weight = 1.3,
              fillColor = "transparent", label = ~HU_8_NAME) %>% 
  
  # add scale bar
  addMeasure(position = "topright",
             primaryLengthUnit = "meters",
             primaryAreaUnit = "sqmeters",
             activeColor = "#3D535D",
             completedColor = "#7D4479") %>% 
  
  # all O/Egages
  addCircleMarkers(data=gages_sierra, group="USGS gages O_E", 
                   stroke=TRUE, weight=0.3,radius=4,
                   fillOpacity = 0.7,
                   fillColor = "blue",
                   popup=paste0("Site: ", gages_sierra$site,"<br>",
                                "SiteNo: ", gages_sierra$site_no,
                                "<br>", "Date_S: ", gages_sierra$date_s,
                                "<br>", "Date_E: ", gages_sierra$date_e),
                   clusterOptions = markerClusterOptions(),
                   clusterId = "gagesCluster") %>%
  # add RANA samples
  addCircleMarkers(data=frogs, group="Rana Samples",
                   lng = ~lon, lat=~lat,opacity = 0.5,
                   popup=paste0("Locality: ", frogs$Locality, "<br>",
                                "HUC12: ", frogs$HUC_12, 
                                "<br>","SampleID: ",frogs$SampleID,
                                "<br>", "SPP_ID: ",frogs$SPP_ID,
                                "<br>", "Elev (m): ", frogs$elev_m, "<br>",
                                "StreamName: ", frogs$GNIS_NAME),
                   weight=0.6,radius=10, stroke=TRUE,
                   fillColor = ifelse(frogs$SPP_ID=="RABO" | frogs$SPP_pc1=="RABO", "yellow", "dodgerblue")) %>%
  hideGroup("Peek Samples") %>% 
  
  addLayersControl(
    baseGroups = c("Topo","ESRI Aerial"),
    overlayGroups = c("HUC8", "USGS gages O_E", "Rana Samples"),
    options = layersControlOptions(collapsed = T))

aMAP
```
-->

### Distance Matrix between Sites

Calc. distance between sites using distance matrix. This works and gives geo distances (**not river distances**), but could be useful for comparing testing (*Euclidean vs. river networks*). Also check out `geosphere` package for additional functions of daylength, dist2lines, and random sampling of lat/longs.

```{r calc_dist_matrix, eval=T, echo=F}
# make function
ReplaceLowerOrUpperTriangle <- function(m, triangle.to.replace){
  # If triangle.to.replace="lower", replaces the lower triangle of a square matrix with its upper triangle.
  # If triangle.to.replace="upper", replaces the upper triangle of a square matrix with its lower triangle.
  
  if (nrow(m) != ncol(m)) stop("Supplied matrix must be square.")
  if      (tolower(triangle.to.replace) == "lower") tri <- lower.tri(m)
  else if (tolower(triangle.to.replace) == "upper") tri <- upper.tri(m)
  else stop("triangle.to.replace must be set to 'lower' or 'upper'.")
  m[tri] <- t(m)[tri]
  return(m)
}

GeoDistanceInMetresMatrix <- function(df.geopoints){
  # Returns a matrix (M) of distances between geographic points.
  # M[i,j] = M[j,i] = Distance between (df.geopoints$lat[i], df.geopoints$lon[i]) and
  # (df.geopoints$lat[j], df.geopoints$lon[j]).
  # The row and column names are given by df.geopoints$name.
  
  GeoDistanceInMetres <- function(g1, g2){
    # Returns a vector of distances. (But if g1$index > g2$index, returns zero.)
    # The 1st value in the returned vector is the distance between g1[[1]] and g2[[1]].
    # The 2nd value in the returned vector is the distance between g1[[2]] and g2[[2]]. Etc.
    # Each g1[[x]] or g2[[x]] must be a list with named elements "index", "lat" and "lon".
    # E.g. g1 <- list(list("index"=1, "lat"=12.1, "lon"=10.1), list("index"=3, "lat"=12.1, "lon"=13.2))
    DistM <- function(g1, g2){
      require("Imap")
      return(ifelse(g1$index > g2$index, 0, gdist(lat.1=g1$lat, lon.1=g1$lon, lat.2=g2$lat, lon.2=g2$lon, units="m")))
    }
    return(mapply(DistM, g1, g2))
  }
  
  n.geopoints <- nrow(df.geopoints)
  
  # The index column is used to ensure we only do calculations for the upper triangle of points
  df.geopoints$index <- 1:n.geopoints
  
  # Create a list of lists
  list.geopoints <- by(df.geopoints[,c("index", "lat", "lon")], 1:n.geopoints, function(x){return(list(x))})
  
  # Get a matrix of distances (in metres)
  mat.distances <- ReplaceLowerOrUpperTriangle(outer(list.geopoints, list.geopoints, GeoDistanceInMetres), "lower")
  
  # Set the row and column names
  rownames(mat.distances) <- df.geopoints$Locality
  colnames(mat.distances) <- df.geopoints$Locality
  
  return(mat.distances)
}

# then use function: test with American only
unimp_AMER <- filter(unimp_rabo, HU_8_NAME %in% c("South Fork American", "North Fork American"))

frogs_AMER <- filter(frog_pts_nhd, HU_8_NAME %in% c("South Fork American", "North Fork American"))

library(Imap)

dfXY<-frogs_AMER

# calc dist in km
distmatrix<-round(GeoDistanceInMetresMatrix(dfXY[,c(1,6:7)]) / 1000)
h(distmatrix)

# dist matrix in heatmap form
image(1:nrow(distmatrix), 1:ncol(distmatrix), distmatrix, axes = FALSE, 
      xlab="", ylab="", col = terrain.colors(100))
colnames(distmatrix)<-dfXY$Locality
rownames(distmatrix)<-dfXY$Locality
axis(1, 1:nrow(distmatrix), rownames(distmatrix), cex.axis = 0.7, las=3, family="Roboto Condensed")
axis(2, 1:nrow(distmatrix), colnames(distmatrix), cex.axis = 0.5, las=1, family="Roboto Condensed")
text(expand.grid(1:nrow(distmatrix), 1:ncol(distmatrix)), sprintf("%0.1f", distmatrix), cex=0.6, family="Roboto Condensed")
title("Euclidean Distance matrix (km) \n for American Watershed Sites", cex.main=0.8, family="Roboto Condensed")
```

## River Distances for Tributary & Mainstem Reaches {#riverdistances}

Need to assess network distances along lines for both tributary distances and mainstem distances because ultimately the connectivity in mainstem rivers is going to be more crucial when related to impairment and hydrometrics. 

So far the best approach I've been able to use has been the **`riverdist`** package. No other toolset has been quite as easy to implement, but there a few options. I'll provide two examples, one using the Hydrosheds data, and the other using NHD data.

### Using [Hydrosheds](http://www.hydrosheds.org/) Data

To make this a bit easier, I'm going to use some code to select to a specific watershed, download the data layer for that watershed, and crop to the watershed boundary. The basic steps are as follows:

 1. [**Download the Data**](http://www.hydrosheds.org/download): Here I'm just picking the `na_riv_15s.zip (27.86 MB)` shapefile from the *River Network section, and put it in my local project folder.
 2. ~~Unzip the file~~
 3. Read it in!

#### Download the [Hydroshed](http://www.hydrosheds.org/) Data

The Global Hydroshed data contains data on basins, rivers, lakes, drainage direction, elevation, and flow accumulation. You need to register (free), and then you can download the data. This example uses a HydroSheds river layer for **NORTH AMERICA**, available from the [USGS](https://hydrosheds.cr.usgs.gov/). Be aware the file size can be large (10's of MB).

```{r load_hydroshedrivers, eval=F, echo=T}

# LOAD HYDROSHED DATA

library(sf)
library(tidyverse)

# HydroSheds River Layer for all of NORTH AMERICA (from https://hydrosheds.cr.usgs.gov/)

# CAN READ IT ZIPPED!!!
narivs <- st_read(unzip("data/shps/na_riv_15s.zip"), quiet = F) 

# then remove raw files since file is added in memory
file.remove(list.files(pattern = "na_riv_15s*",recursive = F))

```

#### Dissolve and Clip Polygon Boundaries

We need to load a polygon file (in this case a state or watershed), potentially dissolve those boundaries into one, and then crop our river layer to the boundary.

As a quick example, here's how to grab state or county boundaries and dissolve them into a single shapefile/polygon.

**Dissolve State Boundaries**
```{r boundaries_dissolve, eval=T, echo=F}

# STATES: from USA Boundaries dataset
library(USAboundaries)

CA<-us_states(resolution = "high", states = c("California")) %>%
  st_transform(crs = 4326)
OR<-us_states(resolution = "high", states = c("Oregon")) %>%
  st_transform(crs = 4326)

# COUNTIES:
cntys <- us_counties(resolution = "low", states=c("California")) #%>%
  #filter(name=="El Dorado" | name=="Placer" | name=="Nevada")

# HUCS:
h8 <- read_sf(unzip("data/shps/h8_AMR_BEA_YUB.zip"), quiet = T) %>% st_transform(crs=4326)

# then remove raw files since file is added in memory
file.remove(list.files(pattern = "h8_AMR_BEA_YUB*",recursive = F))

# union: dissolves features into one (assuming same CRS/geometries)
ca_or<-st_union(x = CA, y = OR) 

# dissolve the HUCS into one polygon
h8_diss <- st_union(h8, by_feature = FALSE) # dissolve single OR

# dissolve by group_feature
#h10<-h12_s %>% group_by(HU_10_NAME) %>% summarize 

# quick test plot
plot(st_geometry(ca_or), axes=T, border="black", lwd=2)
plot(st_geometry(CA), add=T, col=Imap::col.alpha("skyblue",0.2), border="gray")
plot(st_geometry(OR), add=T, col=Imap::col.alpha("forestgreen",0.2), border="gray")
plot(st_geometry(cntys), add=T, border=Imap::col.alpha("purple2",0.3))
plot(st_geometry(h8_diss), add=T, border=Imap::col.alpha("maroon",0.7), lwd=2)
# add a 0.5 km buffer
plot(st_buffer(ca_or, dist = 0.5), add = TRUE, border = 'darkblue')

title("A simple map of CA and OR (with 0.5 km buffer)",
      family="Roboto Condensed")

```

```{r test_chunk_map_diff_rivers, echo=F, eval=F}
# THIS CHUNK FOR TESTING ONLY
# HUC8:
h8 <- read_sf(unzip("data/shps/h8_AMR_BEA_YUB.zip"), quiet = T) %>% st_transform(us_laea_proj)

# then remove raw files since file is added in memory
file.remove(list.files(pattern = "h8_AMR_BEA_YUB*",recursive = F))

# MAJ RIVER: NFA
majrivs <- read_sf("data/shps/MajRivers_SNMdc_H12dsslv.shp", quiet = F) %>% st_transform(us_laea_proj) %>% 
  filter(grepl("North Fork American River", FIRST_HYDN))
#file.remove(list.files(pattern = "H10_named*",recursive = F))

# HYDROSHED RIVERS: BEAR/NFA/MFA/YUB:
hydroshedrivs <- read_sf(unzip("data/shps/rivs_n_sierra_hydroshed.zip"), quiet = F) %>% st_transform(us_laea_proj)
file.remove(list.files(pattern = "rivs_n_sierra_hydroshed*",recursive = F))

# MAINSTEM ONLY (NHD) RIVERS: 
rivNFA <- read_sf("data/shps/rivs_mainstem_NFA_nhd.shp", quiet = T) %>%
   st_transform(us_laea_proj)

rivMFA <- read_sf("data/shps/rivs_mainstem_MFA_nhd.shp", quiet = T) %>%
   st_transform(us_laea_proj)

# plot
plot(st_geometry(h8), axes=T, col=Imap::col.alpha("skyblue",0.4), border="gray")
plot(st_geometry(majrivs), col="darkblue", add=T, lwd=2)
plot(st_geometry(hydroshedrivs), col=Imap::col.alpha("red2",0.7),add=T)
plot(st_geometry(rivMFA), col=Imap::col.alpha("blue",0.7), lwd=2, add=T)
plot(st_geometry(rivNFA), col=Imap::col.alpha("blue",0.7), lwd=2, add=T)
title("Selected River Networks",family="Roboto Condensed")

# crop by selected H8
#h12_s <- st_intersection(h12, h8) #%>% distinct(HUC_12,.keep_all = T)

# dissolve by H10
#h10<-h12_s %>% group_by(HU_10_NAME) %>% summarize %>% distinct(HUC_12,.keep_all = T)

# replot
# plot(st_geometry(h10), axes=T, col=Imap::col.alpha("purple",0.4), border="darkblue", lwd=3)
# plot(st_geometry(h12_s), axes=T, border="gray", col=NA, add=T)
# plot(st_geometry(h8), add=T, border="darkblue")

```

**Clip Rivers (lines) by Boundaries (polygons)**

For this we can use the intersect function, and clip or crop our river data to a specificy polygon boundary (e.g., state or watershed).

```{r intersect_boundaries_hydrosheds, echo=T, eval=T}

# intersect: crops one feature to the other: STATE
# hydrorivs_ca_or <- st_intersection(narivs, ca_or) # this takes AWHILE (2-3 min)

# intersect by Northern Sierra HUC8's (American/Yuba/Bear)
#hydrorivs_n_sierra <- st_intersection(narivs, h8_diss)

# WRITE FILES:
#write_sf(hydrorivs_ca_or, "data/shps/hydroshed_rivs_ca_or.shp")
#write_sf(hydrorivs_n_sierra, "data/shps/hydroshed_rivs_n_sierra.shp")

# if above alread done, just reload the data here:
hydrorivs_ca_or<-st_read(unzip("data/shps/hydroshed_rivs_ca_or.zip"), 
                         quiet = T) %>% st_transform(crs=4326)
file.remove(list.files(pattern = "hydroshed_rivs_ca_or*",recursive = F))

hydrorivs_n_sierra<-st_read(unzip("data/shps/hydroshed_rivs_n_sierra.zip"), 
                         quiet = T) %>% st_transform(crs=4326)
file.remove(list.files(pattern = "hydroshed_rivs_n_sierra*",recursive = F))

# quick plot
plot(st_geometry(hydrorivs_ca_or), col="blue", axes=T)
plot(st_geometry(hydrorivs_n_sierra), col="magenta", add=T)

```

Done!

```{r test_map_h8_rivs, eval=F, echo=F}
# get map range from this layer:
mapRange <- c(range(st_coordinates(h8)[,1]),range(st_coordinates(h8)[,2]))


# HYDROSHEDS Layer (RIVERS) # includes YUB, BEAR, AMER
#majrivs <- st_read("data/shps/rivs_n_sierra_hydroshed.shp") %>% 
majrivs <- st_read("data/shps/rivs_CA_OR_hydroshed.shp") %>% 
  st_transform(crs = 4326) # convert to WSG84

plot(st_geometry(majrivs), col="blue")

# HUC8 Layer
h8 <- st_read("data_output/shps/HUC8_named_westcoast.shp", quiet = T) %>% 
  #filter(grepl(pattern = "NORTH FORK FEATHER|FORK AMERICAN|YUBA|BEAR",HU_8_NAME, ignore.case = T))
  filter(grepl(pattern = "NORTH FORK AMERICAN",HU_8_NAME, ignore.case = T))

plot(st_geometry(h8), border="orange", add=T, lwd=4, fill="orange")
```

### Using NHD Data

The code used to download the NHD River data is taken from an excellent set of tools by folks over at USGS. See this cool little post on assessing precipitation from Hurricane Harvey ([gist](https://gist.github.com/ldecicco-USGS/56262f3809f0807cb523d7105cb790a9)).

#### The Download NHDFlowline Function

 - Here's the function required to download the NHD data, note the default downloads stream layers with a stream order of 1, so the finest scale possible:
 
```{r getNHD_flowlines_function, eval=T, echo=T}

library(geoknife)
library(dataRetrieval)
library(httr)

get_flowlines <- function(streamorder, mapRange){
  postURL <- "https://cida.usgs.gov/nwc/geoserver/nhdplus/ows"
  
  filterXML <- paste0('<?xml version="1.0"?>',
                '<wfs:GetFeature xmlns:wfs="http://www.opengis.net/wfs" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:gml="http://www.opengis.net/gml" service="WFS" version="1.1.0" outputFormat="shape-zip" xsi:schemaLocation="http://www.opengis.net/wfs http://schemas.opengis.net/wfs/1.1.0/wfs.xsd">',
                  '<wfs:Query xmlns:feature="https://gov.usgs.cida/nhdplus" typeName="feature:nhdflowline_network" srsName="EPSG:4326">',
                    '<ogc:Filter xmlns:ogc="http://www.opengis.net/ogc">',
                      '<ogc:And>',
                        '<ogc:PropertyIsGreaterThan>',
                          '<ogc:PropertyName>streamorde</ogc:PropertyName>',
                          '<ogc:Literal>',streamorder-1,'</ogc:Literal>',
                        '</ogc:PropertyIsGreaterThan>',
                        '<ogc:BBOX>',
                          '<ogc:PropertyName>the_geom</ogc:PropertyName>',
                          '<gml:Envelope>',
                            '<gml:lowerCorner>',mapRange[3]," ",mapRange[1],'</gml:lowerCorner>',
                            '<gml:upperCorner>',mapRange[4]," ",mapRange[2],'</gml:upperCorner>',
                          '</gml:Envelope>',
                        '</ogc:BBOX>',
                      '</ogc:And>',
                    '</ogc:Filter>',
                  '</wfs:Query>',
                '</wfs:GetFeature>')

  destination = file.path(tempdir(),"nhdflowline_network.zip")
  file <- POST(postURL, body = filterXML, write_disk(destination, overwrite=T))

  filePath <- tempdir()
  print("unzipping...")
  unzip(destination, exdir = filePath)
  
  flowLines <- st_read(filePath, layer = 'nhdflowline_network')
  #flowLines = readOGR(filePath, layer='nhdflowline_network')
  
  return(flowLines)
}

```

#### Download NHD by a Specific Boundary

Here's the code to download based on a specific boundary or polygon, for this example I'm using HUC8 boundaries. It's possible to change the scale or stream order you are downloading in the flowlines. Here's a comparison of 4 different scales.
 
```{r get_NHD, echo=T, eval=F}

## OPTION 1: By State/County --------------------------------------

# set the state and county names of interest
state_names <- c("california")
co_names <- c("butte", "placer", "el dorado", "nevada", "yuba", "sierra", "plumas")

# filter state and county shapes
states <- map_data("state") %>%
  filter(region %in% state_names)
counties <- map_data("county",state_names) %>% 
  filter(subregion %in% co_names)

# get lat/long from counties in question as range for flowlines
mapRange <- c(range(counties$long),range(counties$lat))

## OPTION 2: By HUC/Watershed Boundary ---------------------------
h8 <- read_sf(unzip("data/shps/h8_AMR_BEA_YUB.zip"), quiet = F) %>%
  st_transform(crs=4326) #%>% 
  #filter(HU_8_NAME=="North Fork American")

# then remove raw files since file is added in memory
file.remove(list.files(pattern = "h8_AMR_BEA_YUB*",recursive = F))

# get map range from this layer for flowlines call
mapRange <- c(range(st_coordinates(h8)[,1]),range(st_coordinates(h8)[,2]))


# Quick MAP  ---------------------------
ggplot() + 
  geom_polygon(data=states, aes(x = long, y = lat, group = group), 
               color = "gray30", lwd=2, fill=NA) +
  geom_polygon(data=counties, aes(x = long, y = lat, group = group), 
               fill = NA, show.legend = F, color="gray50", lwd=0.4) +  
  geom_sf(data=h8, aes(fill=HU_8_NAME), alpha=0.3, color="forestgreen")+
  coord_sf()
  #coord_quickmap(xlim = mapRange[c(1:2)], ylim = mapRange[c(3:4)])

# NOW GET NHD DATA: --------------------------------------

# can take awhile depending on size and stream order, 
# finest scale is stream order of 1

rivers <- get_flowlines(4, mapRange)

# Check with SF Plot: --------------------------------------

# load metadat
metadat<- read_csv("data_output/rapture06_metadata_revised.csv") %>% arrange(Seq)

plot(st_geometry(rivers), col="dodgerblue", axes=T)
points(y=metadat$lat, x=metadat$lon, bg="yellow", pch=21)
plot(st_geometry(h8), add=TRUE, border="maroon")

# Make a Cowplot To Compare Stream Order/Density ------------
library(cowplot)

rivers <- get_flowlines(1, mapRange)
gg1 <- ggplot() + 
  geom_sf(data=rivers, col="blue", lwd=0.4) +
  geom_point(data=metadat, aes(x=lon, y=lat), fill="gray", pch=21) +
  geom_sf(data=h8, fill=NA, color="maroon", lwd=0.7, alpha=0.6) + theme_bw(base_family = "Roboto Condensed")+ labs(title="NHD Stream Order=1")+
  coord_sf(xlim = mapRange[c(1:2)], ylim = mapRange[c(3:4)])
gg1

rivers <- get_flowlines(2, mapRange)
gg2 <- ggplot() + 
  geom_sf(data=rivers, col="blue", lwd=0.4) +
  geom_point(data=metadat, aes(x=lon, y=lat), fill="gray", pch=21) +
  geom_sf(data=h8, fill=NA, color="maroon", lwd=0.7, alpha=0.6) + theme_bw(base_family = "Roboto Condensed")+ labs(title="NHD Stream Order=2")+
  coord_sf(xlim = mapRange[c(1:2)], ylim = mapRange[c(3:4)])
gg2

rivers <- get_flowlines(3, mapRange)
gg3 <- ggplot() + 
  geom_sf(data=rivers, col="blue", lwd=0.4) +
  geom_point(data=metadat, aes(x=lon, y=lat), fill="gray", pch=21) +
  geom_sf(data=h8, fill=NA, color="maroon", lwd=0.7, alpha=0.6) + theme_bw(base_family = "Roboto Condensed")+ labs(title="NHD Stream Order=3")+
  coord_sf(xlim = mapRange[c(1:2)], ylim = mapRange[c(3:4)])
gg3

rivers <- get_flowlines(4, mapRange)
gg4 <- ggplot() + 
  geom_sf(data=rivers, col="blue", lwd=0.4) +
  geom_point(data=metadat, aes(x=lon, y=lat), fill="gray", pch=21) +
  geom_sf(data=h8, fill=NA, color="maroon", lwd=0.7, alpha=0.6) + theme_bw(base_family = "Roboto Condensed")+ labs(title="NHD Stream Order=4")+
  coord_sf(xlim = mapRange[c(1:2)], ylim = mapRange[c(3:4)])
gg4

# put all plots together
cowplot::plot_grid(gg1, gg2, gg3, gg4, nrow = 2)
# getting an error here sometimes, just redraw a few times
#("Error in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y,:  polygon edge not found")

# save
#ggsave(filename="figs/nhd_stream_order_comparison.png", width = 9, height = 7, units = "in", dpi = 200)

# Save Data: --------------------------------------

# save rivers to rdata file:
#saveRDS(rivers, file = "data_output/nhd_rivs_nfa.rds")

```

![cowplot](../figs/nhd_stream_order_comparison.png)

In my case, if I want to look at full distances between tributaries, the `Stream Order=1` is probably required. However, if only assessing distances along mainstem, probably `Stream Order=4` would be appropriate.

#### Clip NHD by a Specific Boundary

Now we've downloaded a geneal area, we can clip the layer by the exact boundary. In this example, the *North Fork American*.

```{r clipByWatershed, eval=F, echo=T}

# generate the data we need:
rivers <- get_flowlines(4, mapRange)

# select NFA
h8_nfa <- h8 %>% filter(HU_8_NAME=="North Fork American")

# select BEAR ("Upper Bear") or YUBA "Upper Yuba"
h8_nfa <- h8 %>% filter(HU_8_NAME=="Upper Yuba")

# get map range from this layer for flowlines call
mapRange <- c(range(st_coordinates(h8_nfa)[,1]),range(st_coordinates(h8_nfa)[,2]))

# CLIP
riv_clip <- st_intersection(rivers, h8_nfa)

# LOAD FROG DATA
# get XY info and filter NA's out first:
metadat<- read_csv("data_output/rapture06_metadata_revised.csv") %>% 
  filter(!is.na(lon), SPP_ID=="RABO" | SPP_pc1=="RABO") %>% # get rid of NAs / non-RABO
  select(-HU_8_NAME, -HUC_8) %>%  # drop conflicting cols
  st_as_sf(coords = c("lon", "lat"), crs = 4326) # make sf
  #st_transform(crs = us_laea_proj) # convert to utms:

# CLIP TO WATERSHEDS
metadat_clip <- st_intersection(metadat, h8_nfa)

# PLOT
plot(st_geometry(h8_nfa), border="gray50", lwd=2, axes=T)
plot(st_geometry(riv_clip), col="dodgerblue", add=T)
plot(st_geometry(metadat_clip), pch=21, bg="yellow2", add=T)

# make a projected ALB version for riverdist
rivs_nfa_alb <- st_transform(riv_clip, us_laea_proj)

## ggplot version
ggplot() + 
  geom_sf(data=riv_clip, col="blue", lwd=0.4) +
  geom_sf(data=metadat_clip, pch=21, color="gray20", alpha=0.3, size=0.5) +
  geom_sf(data=h8_nfa, fill=NA, color="maroon", lwd=0.7, alpha=0.6) + theme_bw(base_family = "Roboto Condensed")+ labs(title="Yuba Watershed, NHD Stream Order=4")+
  coord_sf(xlim = mapRange[c(1:2)], ylim = mapRange[c(3:4)])

ggsave(filename="figs/yuba_watershed_NHD4.png", width=9, height = 6.6, units = "in", dpi=200)

# rename if necessary
rivs_yuba_alb <- rivs_nfa_alb

# write it out
write_sf(rivs_yuba_alb, "data/shps/rivs_nhd4_yuba.shp")

```

![yub](../figs/yuba_watershed_NHD4.png)
![bear](../figs/bear_watershed_NHD4.png)
![nfa](../figs/nfa_watershed_NHD4.png) 

  
### Calculating River Distances

First we need to load a shapefile with a river network of some type. This example uses the Hydrosheds data cropped to the North Fork American watershed. First we load and then clean the network topology so we can snap points and calculate distances along the network.

```{r rivernetwork, echo=T, eval=T}
library(riverdist)
# this to read in shapefile for riv dist
# only works w/ projected coordinate system, use albers equal area: us_aeqd_proj or # us_laea_proj 
rivs <- line2network(path="data/shps/", layer="rivs_nhd4_yuba", reproject = us_aeqd_proj )

# plot of all the segments
plot(x=rivs)

# check topology (nodes)
topologydots(rivers=rivs)

# clean up: remove duplicate segs
# rivers <- removeduplicates(rivs)

# trim if necessary
#rivers2 <- riverdist::trimriver(rivers = rivs_fixed,trimto = c(1:11,19:20,23,25:28))
#plot(rivers2)

# do a clean up:
# rivs_fixed <- cleanup(rivers = rivers2)

  # here we dissolve segments
  # insert vertices at 300 m min distance,
  # ID the river mouth, and check for unconnected segments.
  # Optional: remove additonal segments
  # Optional: check for braiding
  # Optional: build segment routes (can then use point data w river coords with "ptshp2segvert()" or "xy2segvert")

#save(rivs_fixed, file="data/shps/rivs_nhd4_yuba_fixed.rda")

load(file="data/shps/rivs_nhd4_yuba_fixed.rda")

#par(mfrow=c(1,2))
topologydots(rivers=rivs)
graphics::title("Raw River Topology", family="Roboto Condensed")
topologydots(rivs_fixed)
graphics::title("Clean River Topology", family="Roboto Condensed")
#dev.off()
```

#### Snap Points to Nearest Line

Now that we have a river network, we can snap points to the nearest line, and use that to calculate distances between sites along the river network.

```{r snap_xyData, eval=T, echo=F}

# get h8
h8 <- read_sf(unzip("data/shps/h8_AMR_BEA_YUB.zip"), quiet = T) %>%
  st_transform(crs=4326) #%>% 
  #filter(HU_8_NAME=="North Fork American")
file.remove(list.files(pattern = "h8_AMR_BEA_YUB*",recursive = F))

# select HUC8
#h8_nfa <- h8 %>% filter(HU_8_NAME=="North Fork American")
h8_nfa <- h8 %>% filter(HU_8_NAME=="Upper Yuba")

# get map range from this layer for flowlines call
mapRange <- c(range(st_coordinates(h8_nfa)[,1]),range(st_coordinates(h8_nfa)[,2]))

# get XY info in:
metadat<- read_csv("data_output/rapture06_metadata_revised.csv") %>% 
  filter(!is.na(lon), SPP_ID=="RABO" | SPP_pc1=="RABO") %>% # get rid of NAs and non-RABO
  #filter(grepl("NFA|MFA|RUB|NFMFA", Locality)) %>% 
  filter(grepl("NFY|MFY|SFY", Locality)) %>%
  #filter(grepl("BEAR", Locality)) %>% 
  select(-HU_8_NAME, -HUC_8) %>%  # drop conflicting cols
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%  # make sf
  st_transform(crs = us_aeqd_proj) # convert to utms:

# add COORDS
metadat$X <- st_coordinates(metadat)[,1]
metadat$Y <- st_coordinates(metadat)[,2]

# run this to snap points to line (and see distrib)
frog_riv <- xy2segvert(x=metadat$X, y=metadat$Y, rivers=rivs_fixed)
head(frog_riv)
hist(frog_riv$snapdist/1000, breaks=50,main="Point Snapping dist. (km)", col="skyblue3", xlab="Snapping Distance", family="Roboto Condensed")

# add vertices
metadat <- bind_cols(metadat, frog_riv) %>% 
  distinct(Locality,.keep_all = T)

# POINTS ON MAP
plot(x=rivs_fixed)
#zoomtoseg(seg=c(63, 7), rivers=rivs_fixed)
points(metadat$X, metadat$Y, pch=21, col="red") # raw coords
riverpoints(seg=frog_riv$seg, vert=frog_riv$vert, rivers=rivs_fixed, pch=22, cex=0.5,
            bg="skyblue") # snapped coords
text(metadat$X, metadat$Y, labels=metadat$vert, pos = 4, family="Roboto Condensed")
#text(metadat$X, metadat$Y, labels=metadat$Locality, col="maroon", pos = 2, family="Roboto Condensed")

# DETECT ROUTES
#detectroute(start=465, end=5, rivers=rivs_fixed)
# riverdistance(startseg=207, startvert=6, endseg=129, endvert=24,
#               rivers=rivs_fixed, map=TRUE)
#riverdistance(startseg=31, startvert=9, endseg=185, endvert=5,
#              rivers=rivs_fixed, map=TRUE)
```

#### Create Distance Matrix

Once points are snapped to the line network, it is possible to extract distances between site pairs, and export.

```{r create_dist_matrix, eval=T, echo=T}

# CREATE MATRIX OF DISTS
dmat <- riverdistancemat(metadat$seg, metadat$vert, rivs_fixed, ID = metadat$Locality ) %>% as.matrix
head(dmat)

# dist matrix in heatmap form
image(1:nrow(dmat), 1:ncol(dmat), dmat, axes = FALSE, 
      xlab="", ylab="", col = terrain.colors(100))
axis(1, 1:nrow(dmat), rownames(dmat), cex.axis = 0.7, las=3, family="Roboto Condensed")
axis(2, 1:nrow(dmat), colnames(dmat), cex.axis = 0.5, las=1, family="Roboto Condensed")
text(expand.grid(1:nrow(dmat), 1:ncol(dmat)), sprintf("%0.1f", dmat/1000), cex=0.6, family="Roboto Condensed")
graphics::title("Mainstem River Distance (km) for Yuba Watershed Sites", cex.main=1, family="Roboto Condensed")

#nfa_dists <- as.data.frame(dmat)
#bear_dists <- as.data.frame(dmat)
yuba_dists <- as.data.frame(dmat)
write_tsv(yuba_dists, "data_output/mainstem_distance_matrix_YUBA.txt") # AMER, BEAR, YUB
```

#### Merge with Existing Data

Now merge this with the existing data set. In this case we are adding mainstem distances (in addition to total distances).

First calculate the mean distance across all pairwise combinations for each site. 

```{r mean_dists, echo=T, eval=F}

load("data_output/fst_dists_all.rda") # full fst_means

#load("data_output/mod_theta100k_fst_dists_yub_amer_bear.rda") # mean values for all

# AMER dist_matrix -------------------------

# read in dist matrix: NFA American HUC8 (NFA, and MFA)
dist_amer <-read_tsv("data_output/mainstem_distance_matrix_AMER.txt") %>% 
  as.matrix()
colnames(dist_amer) <- gsub("-", replacement = "_", colnames(dist_amer))
colnames(dist_amer)<-tolower(colnames(dist_amer))
rownames(dist_amer)<-colnames(dist_amer)

# NFA: calc rowmeans for single site 
dist_nfa <- dist_amer[grepl("nfa",rownames(dist_amer)),grepl("nfa",colnames(dist_amer))]
dist_nfa_means <- tibble("sites"=rownames(dist_nfa),"mean_main_km"= rowMeans(dist_nfa)/1000)

dist_nfa_means$sites <- gsub("nfa_euch_ds", "nfa_euch", dist_nfa_means$sites)
print(dist_nfa_means)

# MFA: calc rowmeans for single site
dist_mfa <- dist_amer[grepl("mfa|nfmfa|rub",rownames(dist_amer)),grepl("mfa|nfmfa|rub",colnames(dist_amer))]
dist_mfa_means <- tibble("sites"=rownames(dist_mfa),"mean_main_km"= rowMeans(dist_mfa)/1000)
dist_mfa_means$sites <- gsub("rub_lc_us", "rub_lcus", dist_mfa_means$sites)
print(dist_mfa_means)

# BEAR dist_matrix -------------------------

# read in dist matrix: BEAR
dist_bear <-read_tsv("data_output/mainstem_distance_matrix_BEAR.txt") %>%
  as.matrix()
colnames(dist_bear) <- gsub("-", replacement = "_", colnames(dist_bear))
colnames(dist_bear)<-tolower(colnames(dist_bear))
rownames(dist_bear)<-colnames(dist_bear)

# calc rowmeans for single dist 
dist_bear_means <- tibble("sites"=rownames(dist_bear),"mean_main_km"= rowMeans(dist_bear)/1000)

dist_bear_means$sites <- gsub("bear_sth2", "bear_stho",dist_bear_means$sites)
dist_bear_means$sites <- gsub("bear_stha", "bear_stho_haw",dist_bear_means$sites)
dist_bear_means

print(dist_bear_means)

# YUBA dist_matrix -------------------------

# read in dist matrix: YUBA
dist_yuba <-read_tsv("data_output/mainstem_distance_matrix_YUBA.txt") %>% 
  as.matrix()
colnames(dist_yuba) <- gsub("-", replacement = "_", colnames(dist_yuba))
colnames(dist_yuba)<-tolower(colnames(dist_yuba))
rownames(dist_yuba)<-colnames(dist_yuba)

# calc rowmeans for single dist 
dist_nfy <- dist_yuba[grepl("nfy",rownames(dist_yuba)),grepl("nfy",colnames(dist_yuba))]
dist_nfy_means <- tibble("sites"=rownames(dist_nfy),"mean_main_km"= rowMeans(dist_nfy)/1000)

print(dist_nfy_means)

# calc rowmeans for single dist 
dist_sfy <- dist_yuba[grepl("sfy|deer",rownames(dist_yuba)),grepl("sfy|deer",colnames(dist_yuba))]
dist_sfy_means <- tibble("sites"=rownames(dist_sfy),"mean_main_km"= rowMeans(dist_sfy)/1000)

print(dist_sfy_means)

# combine all
dist_all_means <- bind_rows(dist_nfy_means, dist_sfy_means,
                            dist_bear_means, dist_nfa_means,
                            dist_mfa_means)
#write_csv(dist_all_means, path="data_output/mainstem_dists_all.csv")

```

Then take that info and combine with the orig `fst_dist` dataset.

```{r merge_dists, echo=T, eval=F}

# join with 
load("data_output/fst_dists_all.rda") # full fst_means for all sites

(fst_dists_comb <- left_join(fst_dists, dist_all_means, by="sites"))

# add the missing values for MFY OH to Oregon (9.67)
fst_dists_comb[12,6] <- 9.67
# add the missing values for NFA_EUCH (mean of us and ds dist: (20.353)
fst_dists_comb[15,6] <- 20.353

# add the missing values for SFA (arbitary 25 for now since single comparison across watershed)
fst_dists_comb[11,6] <- 25

# reorder: 
fst_dists_comb <- fst_dists_comb %>% 
  select(sites:mean_km, mean_main_km,REG, watershed)

#save(fst_dists_comb, file = "data_output/fst_dist_all_mainstem.rda")

```

Can also merge with other metadat/mod data sets.

```{r merge_mod_meandist, eval=F, echo=T}

load("data_output/fst_dist_all_mainstem.rda")
load("data_output/thetas100k_by_site.rda")

#load("data_output/mod_theta100k_fst_dists_yub_amer_bear.rda")

# add the additional metadata:
load("data_output/frog_pts_nhd_comids.rda")

# now fix fst/theta table
fst_dists_comb$Locality <- toupper(fst_dists_comb$sites)

# need to make localities match:
thetas100k$Locality <- toupper(thetas100k$ID)

# check site names:
unique(thetas100k$Locality) %>% sort
unique(fst_dists_comb$Locality) %>% sort

# join
theta100k_fst_dists <- right_join(thetas100k, fst_dists_comb, by="Locality") %>% dplyr::select(Locality, river, watershed, Tw:nsites, REG, fst_mean:mean_main_km, watershed, -reg, -sites, -Tj, -ID, -Tdiff)

# rename NFA_EUCH so it will join with spatial data
theta100k_fst_dists$Locality <- gsub("NFA_EUCH", "NFA_EUCHDS", theta100k_fst_dists$Locality)

# add SCOTCHMAN ck thetas:
theta100k_fst_dists[28,c(4:6)] <- c(0.00666052, 0.00679309, 1947711)

# fix cols
theta100k_fst_dists$Tdiff <- (theta100k_fst_dists$Tp - theta100k_fst_dists$Tw)

theta100k_fst_dists <- select(theta100k_fst_dists, Locality:watershed, Tdiff, Tw:mean_main_km)

# write fst & thetas only
#save(theta100k_fst_dists, file="data_output/theta100k_fst_dists_yub_amer_bear.rda")

# add the additional metadata:
load("data_output/frog_pts_nhd_comids.rda")

# select and fill NA's in ecoregion with Sierra Nevada
frog_pts_nhd <- frog_pts_nhd %>%
  dplyr::select(Locality:SPP_ID,lat:NHD_Tot_DA_sqkm) %>% 
  mutate(EcoRegion=if_else(is.na(EcoRegion), "Sierra Nevada", EcoRegion),
         Locality=gsub("-", "_", Locality))

# rename a few sites:
frog_pts_nhd$Locality <- gsub("BEAR_STHC", "BEAR_STHO", frog_pts_nhd$Locality)
frog_pts_nhd$Locality <- gsub("BEAR_STHA", "BEAR_STHO_HAW", frog_pts_nhd$Locality)
frog_pts_nhd$Locality <- gsub("RUB_LC_US", "RUB_LCUS", frog_pts_nhd$Locality)
frog_pts_nhd$Locality <- gsub("SFY_RockCk","SFY_ROCKCK", frog_pts_nhd$Locality)
frog_pts_nhd$Locality <- gsub("SFY_Scotchman","SFY_SCOTCHMAN", frog_pts_nhd$Locality)
frog_pts_nhd$Locality <- gsub("SFY_ShadyCk","SFY_SHADYCK", frog_pts_nhd$Locality)
frog_pts_nhd$Locality <- gsub("SFY_SpringCk","SFY_SPRINGCK", frog_pts_nhd$Locality)

# join with genomic data: (try left_join here but will have NA's)
mod_dat_nhd <- inner_join(theta100k_fst_dists, frog_pts_nhd, by="Locality") %>% distinct(Locality, .keep_all = T)

# write fst & thetas only
#save(mod_dat_nhd, file="data_output/mod_theta100k_fst_dists_yub_amer_bear.rda")

```


Finally, we can map these data with a terrain or google map background.

```{r simple_ggmap, echo=F, eval=T}



# SIMPLE MAP --------------------------------------------------------------

library(ggmap) # doesn't plot with SF so need to convert
location<-c(mean(st_coordinates(h8_nfa)[,1]),
            mean(st_coordinates(h8_nfa)[,2]))
map1 <- get_map(location=location,crop = F,
                color="bw",
                maptype="terrain",
                source="google",
                zoom=9)

terrain_bg <-ggmap(map1)

# convert metadat to WGS again and add coords
metadat <- metadat %>% st_transform(crs = 4326)
metadat$long <- st_coordinates(metadat)[,1]
metadat$lat <- st_coordinates(metadat)[,2]

# convert river network:
rivs_alb <- st_read("data/shps/rivs_nhd4_nfa.shp", quiet = T) %>% st_transform(crs=4326) %>% 
  as("Spatial") %>% fortify

# convert h8_nfa
h8_nfa.sp <- h8_nfa %>% as("Spatial") %>% fortify

terrain_bg + 
  scale_color_viridis_d() +
  geom_path(data=rivs_alb, aes(x=long, y=lat, group=group), col="blue")+
  labs(x="Longitude (WGS84)", y="Latitude") +   theme_bw() +
  geom_polygon(data=h8_nfa.sp, aes(x=long, y=lat, group=group), fill=NA, color="maroon", lwd=1.2, alpha=0.5) +
  geom_point(data=metadat, aes(x=long, y=lat), fill="yellow", pch=21, size=3) +
  coord_fixed(xlim = mapRange[c(1:2)], ylim = mapRange[c(3:4)], ratio=1.3)

```

Ok, now let's model this with mainstem distances and potentially assess the differences between tributary distances and mainstem. 

Try BRT to see if that is a better tool for pulling out metrics that correspond most with the Fst and theta data.


